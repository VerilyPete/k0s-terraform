name: 'Terraform Apply'

on:
  push:
    branches:
      - main
    paths:
      - 'terraform/**'
  workflow_dispatch:
    inputs:
      environment:
        description: 'Environment to deploy'
        required: true
        default: 'staging'
        type: choice
        options:
          - staging
          - production
      destroy:
        description: 'Destroy infrastructure instead of apply'
        required: false
        default: false
        type: boolean

permissions:
  contents: read
  id-token: write

env:
  TF_VERSION: '1.12.1'
  OCI_CLI_USER: ${{ secrets.OCI_CLI_USER }}
  OCI_CLI_TENANCY: ${{ secrets.OCI_CLI_TENANCY }}
  OCI_CLI_FINGERPRINT: ${{ secrets.OCI_CLI_FINGERPRINT }}
  OCI_CLI_KEY_CONTENT: ${{ secrets.OCI_CLI_KEY_CONTENT }}
  OCI_CLI_REGION: ${{ secrets.OCI_CLI_REGION }}
  # These environment variables are no longer needed - using terraform.tfvars instead

jobs:
  terraform-apply:
    runs-on: ubuntu-latest
    environment: ${{ github.event.inputs.environment || 'staging' }}
    outputs:
      controller_ip: ${{ steps.outputs.outputs.controller_ip }}
      controller_hostname: ${{ steps.outputs.outputs.controller_hostname }}
      environment: ${{ steps.outputs.outputs.environment }}
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: ${{ env.TF_VERSION }}

      - name: Setup OCI CLI
        run: |
          # Install OCI CLI
          curl -L https://raw.githubusercontent.com/oracle/oci-cli/master/scripts/install/install.sh > install.sh
          chmod +x install.sh
          ./install.sh --accept-all-defaults
          rm install.sh
          
          # Configure OCI CLI
          mkdir -p /home/runner/.oci
          echo "${{ secrets.OCI_CLI_KEY_CONTENT }}" > /home/runner/.oci/oci_api_key.pem
          chmod 600 /home/runner/.oci/oci_api_key.pem
          
          cat > /home/runner/.oci/config << EOF
          [DEFAULT]
          user=${{ secrets.OCI_CLI_USER }}
          fingerprint=${{ secrets.OCI_CLI_FINGERPRINT }}
          tenancy=${{ secrets.OCI_CLI_TENANCY }}
          region=${{ secrets.OCI_CLI_REGION }}
          key_file=/home/runner/.oci/oci_api_key.pem
          EOF
          
          chmod 600 /home/runner/.oci/config
          
          # Debug: Check if files were created
          echo "=== Debug: OCI Configuration ==="
          ls -la /home/runner/.oci/
          echo "Private key file exists:" 
          test -f /home/runner/.oci/oci_api_key.pem && echo "YES" || echo "NO"
          echo "Private key file size:" 
          wc -c /home/runner/.oci/oci_api_key.pem 2>/dev/null || echo "Cannot read file"
          echo "Private key file permissions:" 
          ls -la /home/runner/.oci/oci_api_key.pem
          echo "Private key format check:"
          head -1 /home/runner/.oci/oci_api_key.pem 2>/dev/null || echo "Cannot read private key"
          echo "Private key validation:"
          openssl rsa -in /home/runner/.oci/oci_api_key.pem -check -noout 2>/dev/null && echo "âœ… Private key is valid RSA format" || echo "âŒ Private key validation failed"
          echo "Current working directory: $(pwd)"
          echo "Home directory: $HOME"

      - name: Determine environment
        id: env
        run: |
          if [ "${{ github.event_name }}" = "workflow_dispatch" ]; then
            echo "environment=${{ github.event.inputs.environment }}" >> $GITHUB_OUTPUT
          else
            echo "environment=staging" >> $GITHUB_OUTPUT
          fi

      - name: Create terraform.tfvars
        working-directory: terraform/environments/${{ steps.env.outputs.environment }}
        run: |
          # Create terraform.tfvars with private key path
          cat > terraform.tfvars << EOF
          # OCI Provider Configuration
          tenancy_ocid       = "${{ secrets.OCI_CLI_TENANCY }}"
          user_ocid          = "${{ secrets.OCI_CLI_USER }}"
          fingerprint        = "${{ secrets.OCI_CLI_FINGERPRINT }}"
          private_key_path   = "/home/runner/.oci/oci_api_key.pem"
          region             = "${{ secrets.OCI_CLI_REGION }}"
          oci_namespace      = "${{ secrets.OCI_NAMESPACE }}"
          EOF
          
          # Add infrastructure configuration
          cat >> terraform.tfvars << EOF
          # Infrastructure Configuration
          compartment_id      = "${{ secrets.OCI_COMPARTMENT_ID }}"
          availability_domain = "${{ secrets.OCI_AVAILABILITY_DOMAIN }}"
          subnet_id          = "${{ secrets.OCI_PRIVATE_SUBNET }}"
          vcn_id             = "${{ secrets.OCI_VCN_ID }}"
          image_id           = "${{ secrets.OCI_CUSTOM_IMAGE }}"
          ssh_public_key     = "${{ secrets.SSH_PUBLIC_KEY }}"
          tailscale_auth_key = "${{ secrets.TAILSCALE_AUTH_KEY }}"
          EOF
          
          # ssh_private_key removed - no longer using provisioners
          
          # No path expansion needed - using absolute paths
          
          # Debug: Show generated terraform.tfvars
          echo "=== Debug: Generated terraform.tfvars ==="
          cat terraform.tfvars

      - name: Verify OCI Configuration
        working-directory: terraform/environments/${{ steps.env.outputs.environment }}
        run: |
          echo "=== Verifying OCI Configuration Before Terraform ==="
          
          # Check private key file exists
          PRIVATE_KEY_PATH=$(grep private_key_path terraform.tfvars | cut -d'"' -f2)
          echo "Private key path from terraform.tfvars: $PRIVATE_KEY_PATH"
          
          if [ -f "$PRIVATE_KEY_PATH" ]; then
            echo "âœ… Private key file exists at: $PRIVATE_KEY_PATH"
            ls -la "$PRIVATE_KEY_PATH"
            
            # Verify the private key file is not empty and has correct format
            if [ -s "$PRIVATE_KEY_PATH" ]; then
              echo "âœ… Private key file is not empty"
              # Check if it starts with a valid private key header
              if head -1 "$PRIVATE_KEY_PATH" | grep -q "BEGIN.*PRIVATE KEY"; then
                echo "âœ… Private key file has valid format"
              else
                echo "âš ï¸  Private key file format may be incorrect (should start with -----BEGIN...PRIVATE KEY-----)"
              fi
            else
              echo "âŒ Private key file is empty"
              exit 1
            fi
          else
            echo "âŒ Private key file NOT found at: $PRIVATE_KEY_PATH"
            echo "Checking absolute path directory:"
            ls -la /home/runner/.oci/ || echo "/home/runner/.oci directory not found"
            exit 1
          fi

      - name: OCI Backend Configuration Info
        working-directory: terraform/environments/${{ steps.env.outputs.environment }}
        run: |
          echo "=== OCI Backend Configuration ==="
          echo "Using OCI native backend for state management"
          echo "Bucket: terraform-state-${{ steps.env.outputs.environment }}"
          echo "Namespace: ${{ secrets.OCI_NAMESPACE }}"
          echo "Region: ${{ secrets.OCI_CLI_REGION }}"
          echo "Key: k0s-cluster/terraform.tfstate"
          echo "Auth: APIKey (using ~/.oci/config profile DEFAULT)"

      - name: Terraform Init
        working-directory: terraform/environments/${{ steps.env.outputs.environment }}
        run: |
          terraform init \
            -backend-config="namespace=${{ secrets.OCI_NAMESPACE }}" \
            -backend-config="region=${{ secrets.OCI_CLI_REGION }}"

      - name: Terraform Apply
        if: github.event.inputs.destroy != 'true'
        working-directory: terraform/environments/${{ steps.env.outputs.environment }}
        id: apply
        run: |
          terraform apply -auto-approve
          terraform output -json > outputs.json

      - name: Clean up Tailscale entries before destroy
        if: github.event.inputs.destroy == 'true'
        run: |
          echo "ðŸ§¹ Cleaning up Tailscale entries for environment: ${{ steps.env.outputs.environment }}"
          
          # Get all devices from Tailscale API
          echo "Fetching all Tailscale devices..."
          DEVICE_RESPONSE=$(curl -s -H "Authorization: Bearer ${{ secrets.TAILSCALE_API_KEY }}" \
            "https://api.tailscale.com/api/v2/tailnet/-/devices" 2>/dev/null)

          # Check if we got a valid response
          if [ -z "$DEVICE_RESPONSE" ] || [ "$DEVICE_RESPONSE" = "null" ]; then
            echo "âš ï¸  Could not fetch Tailscale devices (API error or no devices)"
            exit 0
          fi

          # Extract all hostnames that match our patterns
          HOSTNAMES_TO_DELETE=$(echo "$DEVICE_RESPONSE" | jq -r '
            if .devices then 
              .devices[] | select(
                (.hostname | test("^k8s-controller-staging")) or
                (.hostname | test("^k8s-worker-[0-9]+-staging"))
              ) | .hostname
            else 
              empty 
            end' 2>/dev/null)

          # Also add the specific environment nodes
          ENVIRONMENT_HOSTNAMES=(
            "k8s-controller-${{ steps.env.outputs.environment }}"
            "k8s-worker-1-${{ steps.env.outputs.environment }}"
            "k8s-worker-2-${{ steps.env.outputs.environment }}"
          )

          # Combine all hostnames into one list
          ALL_HOSTNAMES=()
          if [ -n "$HOSTNAMES_TO_DELETE" ]; then
            while IFS= read -r hostname; do
              [ -n "$hostname" ] && ALL_HOSTNAMES+=("$hostname")
            done <<< "$HOSTNAMES_TO_DELETE"
          fi
          
          # Add environment-specific hostnames
          for hostname in "${ENVIRONMENT_HOSTNAMES[@]}"; do
            ALL_HOSTNAMES+=("$hostname")
          done

          # Remove duplicates
          UNIQUE_HOSTNAMES=($(printf "%s\n" "${ALL_HOSTNAMES[@]}" | sort -u))

          if [ ${#UNIQUE_HOSTNAMES[@]} -eq 0 ]; then
            echo "â„¹ï¸  No matching Tailscale devices found to clean up"
            exit 0
          fi

          echo "Found ${#UNIQUE_HOSTNAMES[@]} devices to remove:"
          printf "  - %s\n" "${UNIQUE_HOSTNAMES[@]}"
          echo ""
          
          # Remove each device with enhanced error handling
          REMOVAL_COUNT=0
          FAILED_REMOVALS=()
          
          for hostname in "${UNIQUE_HOSTNAMES[@]}"; do
            echo "Removing $hostname from Tailscale..."

            # Extract nodeId for this specific hostname with error handling
            nodeId=""
            jq_output=$(echo "$DEVICE_RESPONSE" | jq -r --arg hostname "$hostname" '
              if .devices then 
                (.devices[] | select(.hostname == $hostname) | .nodeId // empty)
              else 
                empty 
              end' 2>&1)
            jq_exit_code=$?
            
            if [ $jq_exit_code -ne 0 ]; then
              echo "  âŒ jq command failed for $hostname (exit code: $jq_exit_code)"
              echo "  jq error: $jq_output"
              FAILED_REMOVALS+=("$hostname (jq error)")
              continue
            fi
            
            nodeId="$jq_output"

            if [ -n "$nodeId" ] && [ "$nodeId" != "null" ] && [ "$nodeId" != "" ]; then
              echo "  Found device $hostname with nodeId: $nodeId"
              
              # Validate nodeId format (should be alphanumeric)
              if [[ ! "$nodeId" =~ ^[a-zA-Z0-9]+$ ]]; then
                echo "  âŒ Invalid nodeId format: $nodeId"
                FAILED_REMOVALS+=("$hostname (invalid nodeId)")
                continue
              fi
              
              # Make delete request with better error handling
              DELETE_RESPONSE=$(curl -s -w "\n%{http_code}" -X DELETE \
                -H "Authorization: Bearer ${{ secrets.TAILSCALE_API_KEY }}" \
                "https://api.tailscale.com/api/v2/device/$nodeId" 2>&1)
              curl_exit_code=$?
              
              if [ $curl_exit_code -ne 0 ]; then
                echo "  âŒ curl command failed for $hostname (exit code: $curl_exit_code)"
                echo "  curl error: $DELETE_RESPONSE"
                FAILED_REMOVALS+=("$hostname (curl error)")
                continue
              fi
              
              # Parse response and status code
              http_code=$(echo "$DELETE_RESPONSE" | tail -n1)
              response_body=$(echo "$DELETE_RESPONSE" | head -n -1)
              
              echo "  HTTP Status: $http_code"
              if [ -n "$response_body" ]; then
                echo "  Response: $response_body"
              fi
              
              if [[ "$http_code" == "200" ]] || [[ "$http_code" == "204" ]]; then
                echo "  âœ… Successfully removed $hostname"
                REMOVAL_COUNT=$((REMOVAL_COUNT + 1))
              else
                echo "  âš ï¸  Failed to remove $hostname (HTTP $http_code)"
                FAILED_REMOVALS+=("$hostname (HTTP $http_code)")
              fi
            else
              echo "  â„¹ï¸  $hostname not found in Tailscale (nodeId: '$nodeId')"
            fi
          done

          echo ""
          echo "ðŸŽ‰ Tailscale cleanup summary:"
          echo "  Total devices: ${#UNIQUE_HOSTNAMES[@]}"
          echo "  Successfully removed: $REMOVAL_COUNT"
          echo "  Failed removals: ${#FAILED_REMOVALS[@]}"
          
          if [ ${#FAILED_REMOVALS[@]} -gt 0 ]; then
            echo "  Failed devices:"
            printf "    - %s\n" "${FAILED_REMOVALS[@]}"
            
            # Exit with error if critical failures occurred
            if [ ${#FAILED_REMOVALS[@]} -eq ${#UNIQUE_HOSTNAMES[@]} ]; then
              echo "âŒ All device removals failed - this may indicate an API or authentication issue"
              exit 1
            else
              echo "âš ï¸  Some devices failed to remove but continuing with terraform destroy"
            fi
          fi

      - name: Terraform Destroy
        if: github.event.inputs.destroy == 'true'
        working-directory: terraform/environments/${{ steps.env.outputs.environment }}
        run: terraform destroy -auto-approve

      - name: Parse Terraform Outputs
        if: github.event.inputs.destroy != 'true'
        id: outputs
        working-directory: terraform/environments/${{ steps.env.outputs.environment }}
        run: |
          CONTROLLER_IP=$(jq -r '.cluster_info.value.controller.private_ip' outputs.json)
          CONTROLLER_HOSTNAME=$(jq -r '.cluster_info.value.controller.hostname' outputs.json)
          
          echo "controller_ip=$CONTROLLER_IP" >> $GITHUB_OUTPUT
          echo "controller_hostname=$CONTROLLER_HOSTNAME" >> $GITHUB_OUTPUT
          echo "environment=${{ steps.env.outputs.environment }}" >> $GITHUB_OUTPUT

      - name: Terraform Apply Summary
        if: github.event.inputs.destroy != 'true'
        run: |
          echo "============================================="
          echo "Terraform Apply Complete - ${{ steps.env.outputs.environment }}"
          echo "============================================="
          echo ""
          echo "Controller: ${{ steps.outputs.outputs.controller_hostname }}"
          echo "Private IP: ${{ steps.outputs.outputs.controller_ip }}"
          echo ""
          echo "Next: K8s cluster setup and application deployment will run in separate job"
          echo "============================================="

  # Call the K8s deployment workflow
  k8s-deployment:
    if: github.event.inputs.destroy != 'true'
    needs: terraform-apply
    uses: ./.github/workflows/k8s-deploy.yml
    with:
      environment: ${{ needs.terraform-apply.outputs.environment }}
      controller_ip: ${{ needs.terraform-apply.outputs.controller_ip }}
      controller_hostname: ${{ needs.terraform-apply.outputs.controller_hostname }}
    secrets: inherit
